dfs.namenode.rpc-address		RPC address that handles all clients requests. In the case of HA/Federation where multiple namenodes exist,     the name service id is added to the name e.g. dfs.namenode.rpc-address.ns1     dfs.namenode.rpc-address.EXAMPLENAMESERVICE     The value of this property will take the form of nn-host1:rpc-port.
dfs.namenode.servicerpc-address		RPC address for HDFS Services communication. BackupNode, Datanodes and all other services should be     connecting to this address if it is configured. In the case of HA/Federation where multiple namenodes exist,     the name service id is added to the name e.g. dfs.namenode.servicerpc-address.ns1     dfs.namenode.rpc-address.EXAMPLENAMESERVICE     The value of this property will take the form of nn-host1:rpc-port.     If the value of this property is unset the value of dfs.namenode.rpc-address will be used as the default.
dfs.namenode.secondary.https-address	0.0.0.0:50091	The secondary namenode HTTPS server address and port.
dfs.datanode.address	0.0.0.0:50010	The datanode server address and port for data transfer.
dfs.datanode.http.address	0.0.0.0:50075	The datanode http server address and port.
dfs.datanode.ipc.address	0.0.0.0:50020	The datanode ipc server address and port.
dfs.namenode.http-address	0.0.0.0:50070	The address and the base port where the dfs namenode web ui will listen on.
dfs.namenode.heartbeat.recheck-interval	300000	This time decides the interval to check for expired datanodes.     With this value and dfs.heartbeat.interval, the interval of     deciding the datanode is stale or not is also calculated.     The unit of this configuration is millisecond.
dfs.datanode.https.address	0.0.0.0:50475	The datanode secure http server address and port.
dfs.namenode.https-address	0.0.0.0:50470	The namenode secure http server address and port.
dfs.datanode.dns.interface	default	The name of the Network Interface from which a data node should      report its IP address. e.g. eth2. This setting may be required for some      multi-homed nodes where the DataNodes are assigned multiple hostnames      and it is desirable for the DataNodes to use a non-default hostname.       Prefer using hadoop.security.dns.interface over      dfs.datanode.dns.interface.
dfs.datanode.dns.nameserver	default	The host name or IP address of the name server (DNS) which a DataNode     should use to determine its own host name.      Prefer using hadoop.security.dns.nameserver over     dfs.datanode.dns.nameserver.
dfs.namenode.fs-limits.max-blocks-per-file	1048576	Maximum number of blocks per file, enforced by the Namenode on         write. This prevents the creation of extremely large files which can         degrade performance.
dfs.namenode.edits.dir	${dfs.namenode.name.dir}	Determines where on the local filesystem the DFS name node       should store the transaction (edits) file. If this is a comma-delimited list       of directories then the transaction file is replicated in all of the        directories, for redundancy. Default value is same as dfs.namenode.name.dir
dfs.namenode.shared.edits.dir		A directory on shared storage between the multiple namenodes   in an HA cluster. This directory will be written by the active and read   by the standby in order to keep the namespaces synchronized. This directory   does not need to be listed in dfs.namenode.edits.dir above. It should be   left empty in a non-HA cluster.
dfs.permissions.superusergroup	supergroup	The name of the group of super-users.     The value should be a single group name.
dfs.block.access.key.update.interval	600	Interval in minutes at which namenode updates its access keys.
dfs.replication	3	Default block replication.    The actual number of replications can be specified when the file is created.   The default is used if replication is not specified in create time.
dfs.namenode.replication.min	1	Minimal block replication.
dfs.client.block.write.retries	3	The number of retries for writing blocks to the data nodes,    before we signal failure to the application.
dfs.client.block.write.replace-datanode-on-failure.policy	DEFAULT	This property is used only if the value of     dfs.client.block.write.replace-datanode-on-failure.enable is true.      ALWAYS: always add a new datanode when an existing datanode is removed.          NEVER: never add a new datanode.      DEFAULT:        Let r be the replication number.       Let n be the number of existing datanodes.       Add a new datanode only if r is greater than or equal to 3 and either       (1) floor(r/2) is greater than or equal to n; or       (2) r is greater than n and the block is hflushed/appended.
dfs.blockreport.split.threshold	1000000	If the number of blocks on the DataNode is below this     threshold then it will send block reports for all Storage Directories     in a single message.      If the number of blocks exceeds this threshold then the DataNode will     send block reports for each Storage Directory in separate messages.      Set to zero to always split.
dfs.namenode.full.block.report.lease.length.ms	300000	The number of milliseconds that the NameNode will wait before invalidating     a full block report lease.  This prevents a crashed DataNode from     permanently using up a full block report lease.
dfs.datanode.directoryscan.threads	1	How many threads should the threadpool used to compile reports   for volumes in parallel have.
dfs.namenode.handler.count	10	The number of Namenode RPC server threads that listen to   requests from clients.   If dfs.namenode.servicerpc-address is not configured then   Namenode RPC server threads listen to requests from all nodes.
dfs.namenode.safemode.threshold-pct	0.999f	Specifies the percentage of blocks that should satisfy      the minimal replication requirement defined by dfs.namenode.replication.min.     Values less than or equal to 0 mean not to wait for any particular     percentage of blocks before exiting safemode.     Values greater than 1 will make safe mode permanent.
dfs.namenode.resource.check.interval	5000	The interval in milliseconds at which the NameNode resource checker runs.     The checker calculates the number of the NameNode storage volumes whose     available spaces are more than dfs.namenode.resource.du.reserved, and     enters safemode if the number becomes lower than the minimum value     specified by dfs.namenode.resource.checked.volumes.minimum.
dfs.namenode.resource.du.reserved	104857600	The amount of space to reserve/require for a NameNode storage directory     in bytes. The default is 100MB.
dfs.namenode.resource.checked.volumes.minimum	1	The minimum number of redundant NameNode storage volumes required.
dfs.hosts		Names a file that contains a list of hosts that are   permitted to connect to the namenode. The full pathname of the file   must be specified.  If the value is empty, all hosts are   permitted.
dfs.hosts.exclude		Names a file that contains a list of hosts that are   not permitted to connect to the namenode.  The full pathname of the   file must be specified.  If the value is empty, no hosts are   excluded.
dfs.namenode.decommission.blocks.per.interval	500000	The approximate number of blocks to process per        decommission interval, as defined in dfs.namenode.decommission.interval.
dfs.namenode.replication.interval	3	The periodicity in seconds with which the namenode computes    replication work for datanodes.
dfs.namenode.accesstime.precision	3600000	The access time for HDFS file is precise upto this value.                 The default value is 1 hour. Setting a value of 0 disables                access times for HDFS.
dfs.client-write-packet-size	65536	Packet size for clients to write
dfs.client.write.exclude.nodes.cache.expiry.interval.millis	600000	The maximum period to keep a DN in the excluded nodes list   at a client. After this period, in milliseconds, the previously excluded node(s) will   be removed automatically from the cache and will be considered good for block allocations   again. Useful to lower or raise in situations where you keep a file open for very long   periods (such as a Write-Ahead-Log (WAL) file) to make the writer tolerant to cluster maintenance   restarts. Defaults to 10 minutes.
dfs.namenode.checkpoint.dir	file://${hadoop.tmp.dir}/dfs/namesecondary	Determines where on the local filesystem the DFS secondary       name node should store the temporary images to merge.       If this is a comma-delimited list of directories then the image is       replicated in all of the directories for redundancy.
dfs.namenode.checkpoint.edits.dir	${dfs.namenode.checkpoint.dir}	Determines where on the local filesystem the DFS secondary       name node should store the temporary edits to merge.       If this is a comma-delimited list of directories then the edits is       replicated in all of the directories for redundancy.       Default value is same as dfs.namenode.checkpoint.dir
dfs.namenode.checkpoint.check.period	60	The SecondaryNameNode and CheckpointNode will poll the NameNode   every 'dfs.namenode.checkpoint.check.period' seconds to query the number   of uncheckpointed transactions.
dfs.namenode.num.checkpoints.retained	2	The number of image checkpoint files (fsimage_*) that will be retained by   the NameNode and Secondary NameNode in their storage directories. All edit   logs (stored on edits_* files) necessary to recover an up-to-date namespace from the oldest retained   checkpoint will also be retained.
dfs.namenode.delegation.token.max-lifetime	604800000	The maximum lifetime in milliseconds for which a delegation        token is valid.
dfs.image.transfer.timeout	60000	Socket timeout for image transfer in milliseconds. This timeout and the related         dfs.image.transfer.bandwidthPerSec parameter should be configured such         that normal image transfer can complete successfully.         This timeout prevents client hangs when the sender fails during         image transfer. This is socket timeout during image transfer.
dfs.image.transfer.bandwidthPerSec	0	Maximum bandwidth used for regular image transfers (instead of         bootstrapping the standby namenode), in bytes per second.         This can help keep normal namenode operations responsive during         checkpointing. The maximum bandwidth and timeout in         dfs.image.transfer.timeout should be set such that normal image         transfers can complete successfully.         A default value of 0 indicates that throttling is disabled.         The maximum bandwidth used for bootstrapping standby namenode is         configured with dfs.image.transfer-bootstrap-standby.bandwidthPerSec.
dfs.image.transfer-bootstrap-standby.bandwidthPerSec	0	Maximum bandwidth used for transferring image to bootstrap standby       namenode, in bytes per second.       A default value of 0 indicates that throttling is disabled. This default       value should be used in most cases, to ensure timely HA operations.       The maximum bandwidth used for regular image transfers is configured       with dfs.image.transfer.bandwidthPerSec.
dfs.client.failover.sleep.base.millis	500	Expert only. The time to wait, in milliseconds, between failover     attempts increases exponentially as a function of the number of     attempts made so far, with a random factor of +/- 50%. This option     specifies the base value used in the failover calculation. The     first failover will retry immediately. The 2nd failover attempt     will delay at least dfs.client.failover.sleep.base.millis     milliseconds. And so on.
dfs.nameservices		Comma-separated list of nameservices.
dfs.nameservice.id		The ID of this nameservice. If the nameservice ID is not     configured or more than one nameservice is configured for     dfs.nameservices it is determined automatically by     matching the local node's address with the configured address.
dfs.internal.nameservices		Comma-separated list of nameservices that belong to this cluster.     Datanode will report to all the nameservices in this list. By default     this is set to the value of dfs.nameservices.
dfs.ha.namenode.id		The ID of this namenode. If the namenode ID is not configured it     is determined automatically by matching the local node's address     with the configured address.
dfs.ha.log-roll.period	120	How often, in seconds, the StandbyNode should ask the active to     roll edit logs. Since the StandbyNode only reads from finalized     log segments, the StandbyNode will only be as up-to-date as how     often the logs are rolled. Note that failover triggers a log roll     so the StandbyNode will be up to date before it becomes active.
dfs.ha.tail-edits.period	60	How often, in seconds, the StandbyNode should check for new     finalized log segments in the shared edits log.
dfs.client.local.interfaces		A comma separated list of network interface names to use     for data transfer between the client and datanodes. When creating     a connection to read from or write to a datanode, the client     chooses one of the specified interfaces at random and binds its     socket to the IP of that interface. Individual names may be     specified as either an interface name (eg "eth0"), a subinterface     name (eg "eth0:0"), or an IP address (which may be specified using     CIDR notation to match a range of IPs).
dfs.namenode.kerberos.internal.spnego.principal	${dfs.web.authentication.kerberos.principal}	The server principal used by the NameNode for web UI SPNEGO     authentication when Kerberos security is enabled. This is     typically set to HTTP/_HOST@REALM.TLD The SPNEGO server principal     begins with the prefix HTTP/ by convention.      If the value is '*', the web server will attempt to login with     every principal specified in the keytab file     dfs.web.authentication.kerberos.keytab.
dfs.web.authentication.kerberos.principal		The server principal used by the NameNode for WebHDFS SPNEGO     authentication.      Required when WebHDFS and security are enabled. In most secure clusters this     setting is also used to specify the values for     dfs.namenode.kerberos.internal.spnego.principal and     dfs.journalnode.kerberos.internal.spnego.principal.
dfs.namenode.write.stale.datanode.ratio	0.5f	When the ratio of number stale datanodes to total datanodes marked     is greater than this ratio, stop avoiding writing to stale nodes so     as to prevent causing hotspots.
dfs.namenode.replication.work.multiplier.per.iteration	2	*Note*: Advanced property. Change with caution.     This determines the total amount of block transfers to begin in     parallel at a DN, for replication, when such a command list is being     sent over a DN heartbeat by the NN. The actual number is obtained by     multiplying this multiplier with the total number of live nodes in the     cluster. The result number is the number of blocks to begin transfers     immediately for, per DN heartbeat. This number can be any positive,     non-zero integer.
dfs.datanode.metrics.logger.period.seconds	600	This setting controls how frequently the DataNode logs its metrics. The     logging configuration must also define one or more appenders for     DataNodeMetricsLog for the metrics to be logged.     DataNode metrics logging is disabled if this value is set to zero or     less than zero.
hadoop.user.group.metrics.percentiles.intervals		A comma-separated list of the granularity in seconds for the metrics     which describe the 50/75/90/95/99th percentile latency for group resolution     in milliseconds.     By default, percentile latency metrics are disabled.
dfs.encrypt.data.transfer.algorithm		This value may be set to either "3des" or "rc4". If nothing is set, then     the configured JCE default on the system is used (usually 3DES.) It is     widely believed that 3DES is more cryptographically secure, but RC4 is     substantially faster.          Note that if AES is supported by both the client and server then this      encryption algorithm will only be used to initially transfer keys for AES.     (See dfs.encrypt.data.transfer.cipher.suites.)
dfs.trustedchannel.resolver.class		TrustedChannelResolver is used to determine whether a channel        is trusted for plain data transfer. The TrustedChannelResolver is       invoked on both client and server side. If the resolver indicates        that the channel is trusted, then the data transfer will not be        encrypted even if dfs.encrypt.data.transfer is set to true. The       default implementation returns false indicating that the channel        is not trusted.
dfs.data.transfer.protection		A comma-separated list of SASL protection values used for secured     connections to the DataNode when reading or writing block data.  Possible     values are authentication, integrity and privacy.  authentication means     authentication only and no integrity or privacy; integrity implies     authentication and integrity are enabled; and privacy implies all of     authentication, integrity and privacy are enabled.  If     dfs.encrypt.data.transfer is set to true, then it supersedes the setting for     dfs.data.transfer.protection and enforces that all connections must use a     specialized encrypted SASL handshake.  This property is ignored for     connections to a DataNode listening on a privileged port.  In this case, it     is assumed that the use of a privileged port establishes sufficient trust.
dfs.journalnode.http-address	0.0.0.0:8480	The address and port the JournalNode HTTP server listens on.     If the port is 0 then the server will start on a free port.
dfs.journalnode.https-address	0.0.0.0:8481	The address and port the JournalNode HTTPS server listens on.     If the port is 0 then the server will start on a free port.
dfs.namenode.audit.loggers	default	List of classes implementing audit loggers that will receive audit events.     These should be implementations of org.apache.hadoop.hdfs.server.namenode.AuditLogger.     The special value "default" can be used to reference the default audit     logger, which uses the configured log system. Installing custom audit loggers     may affect the performance and stability of the NameNode. Refer to the custom     logger's documentation for more details.
dfs.client.mmap.cache.size	256	When zero-copy reads are used, the DFSClient keeps a cache of recently used     memory mapped regions.  This parameter controls the maximum number of     entries that we will keep in that cache.      The larger this number is, the more file descriptors we will potentially     use for memory-mapped files.  mmaped files also use virtual address space.     You may need to increase your ulimit virtual address space limits before     increasing the client mmap cache size.      Note that you can still do zero-copy reads when this size is set to 0.
dfs.datanode.fsdatasetcache.max.threads.per.volume	4	The maximum number of threads per volume to use for caching new data     on the datanode. These threads consume both I/O and CPU. This can affect     normal datanode operations.
dfs.cachereport.intervalMsec	10000	Determines cache reporting interval in milliseconds.  After this amount of     time, the DataNode sends a full report of its cache state to the NameNode.     The NameNode uses the cache report to update its map of cached blocks to     DataNode locations.      This configuration has no effect if in-memory caching has been disabled by     setting dfs.datanode.max.locked.memory to 0 (which is the default).      If the native libraries are not available to the DataNode, this     configuration has no effect.
dfs.namenode.edit.log.autoroll.multiplier.threshold	2.0	Determines when an active namenode will roll its own edit log.     The actual threshold (in number of edits) is determined by multiplying     this value by dfs.namenode.checkpoint.txns.      This prevents extremely large edit files from accumulating on the active     namenode, which can cause timeouts during namenode startup and pose an     administrative hassle. This behavior is intended as a failsafe for when     the standby or secondary namenode fail to roll the edit log by the normal     checkpoint threshold.
dfs.webhdfs.user.provider.user.pattern	^[A-Za-z_][A-Za-z0-9._-]*[$]?$	Valid pattern for user and group names for webhdfs, it must be a valid java regex.
dfs.webhdfs.socket.connect-timeout	60s	Socket timeout for connecting to WebHDFS servers. This prevents a     WebHDFS client from hanging if the server hostname is     misconfigured, or the server does not response before the timeout     expires. Value is followed by a unit specifier: ns, us, ms, s, m,     h, d for nanoseconds, microseconds, milliseconds, seconds,     minutes, hours, days respectively. Values should provide units,     but milliseconds are assumed.
dfs.webhdfs.socket.read-timeout	60s	Socket timeout for reading data from WebHDFS servers. This     prevents a WebHDFS client from hanging if the server stops sending     data. Value is followed by a unit specifier: ns, us, ms, s, m, h,     d for nanoseconds, microseconds, milliseconds, seconds, minutes,     hours, days respectively. Values should provide units,     but milliseconds are assumed.
dfs.client.context	default	The name of the DFSClient context that we should use.  Clients that share     a context share a socket cache and short-circuit cache, among other things.     You should only change this if you don't want to share with another set of     threads.
dfs.domain.socket.path		Optional.  This is a path to a UNIX domain socket that will be used for     communication between the DataNode and local HDFS clients.     If the string "_PORT" is present in this path, it will be replaced by the     TCP port of the DataNode.
dfs.datanode.shared.file.descriptor.paths	/dev/shm,/tmp	Comma separated paths to the directory on which     shared memory segments are created.     The client and the DataNode exchange information via     this shared memory segment.     It tries paths in order until creation of shared memory segment succeeds.
dfs.namenode.audit.log.debug.cmdlist		A comma separated list of NameNode commands that are written to the HDFS     namenode audit log only if the audit log level is debug.
dfs.client.slow.io.warning.threshold.ms	30000	The threshold in milliseconds at which we will log a slow     io warning in a dfsclient. By default, this parameter is set to 30000     milliseconds (30 seconds).
dfs.datanode.slow.io.warning.threshold.ms	300	The threshold in milliseconds at which we will log a slow     io warning in a datanode. By default, this parameter is set to 300     milliseconds.
dfs.namenode.fs-limits.max-xattrs-per-inode	32	Maximum number of extended attributes per inode.
dfs.namenode.fs-limits.max-xattr-size	16384	The maximum combined size of the name and value of an extended attribute     in bytes. It should be larger than 0, and less than or equal to maximum     size hard limit which is 32768.
dfs.namenode.read-lock-reporting-threshold-ms	5000	When a read lock is held on the namenode for a long time,     this will be logged as the lock is released. This sets how long the     lock must be held for logging to occur.
dfs.namenode.startup.delay.block.deletion.sec	0	The delay in seconds at which we will pause the blocks deletion     after Namenode startup. By default it's disabled.     In the case a directory has large number of directories and files are     deleted, suggested delay is one hour to give the administrator enough time     to notice large number of pending deletion blocks and take corrective     action.
dfs.namenode.edekcacheloader.initial.delay.ms	3000	When KeyProvider is configured, the time delayed until the first     attempt to warm up edek cache on NN start up / become active.
dfs.datanode.cache.revocation.timeout.ms	900000	When the DFSClient reads from a block file which the DataNode is     caching, the DFSClient can skip verifying checksums.  The DataNode will     keep the block file in cache until the client is done.  If the client takes     an unusually long time, though, the DataNode may need to evict the block     file from the cache anyway.  This value controls how long the DataNode will     wait for the client to release a replica that it is reading without     checksums.
dfs.namenode.top.num.users	10	Number of top users returned by the top tool
dfs.namenode.top.windows.minutes	1,5,25	comma separated list of nntop reporting periods in minutes
dfs.datanode.transfer.socket.recv.buffer.size	0	Socket receive buffer size for DataXceiver (receiving packets from client     during block writing). This may affect TCP connection throughput.     If it is set to zero or negative value, no buffer size will be set     explicitly, thus enable tcp auto-tuning on some system.     The default value is 0.
dfs.namenode.upgrade.domain.factor	${dfs.replication}	This is valid only when block placement policy is set to     BlockPlacementPolicyWithUpgradeDomain. It defines the number of     unique upgrade domains any block's replicas should have.     When the number of replicas is less or equal to this value, the policy     ensures each replica has an unique upgrade domain. When the number of     replicas is greater than this value, the policy ensures the number of     unique domains is at least this value.
dfs.xframe.value	SAMEORIGIN	This configration value allows user to specify the value for the       X-FRAME-OPTIONS. The possible values for this field are       DENY, SAMEORIGIN and ALLOW-FROM. Any other value will throw an       exception when namenode and datanodes are starting up.
dfs.http.client.retry.policy.spec	10000,6,60000,10	Specify a policy of multiple linear random retry for WebHDFS client,     e.g. given pairs of number of retries and sleep time (n0, t0), (n1, t1),     ..., the first n0 retries sleep t0 milliseconds on average,     the following n1 retries sleep t1 milliseconds on average, and so on.
dfs.namenode.hosts.provider.classname	org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager	The class that provides access for host files.     org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager is used     by default which loads files specified by dfs.hosts and dfs.hosts.exclude.     If org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager is     used, it will load the JSON file defined in dfs.hosts.     To change class name, nn restart is required. "dfsadmin -refreshNodes" only     refreshes the configuration files used by the class.
